---
layout: post
title: 操作系统
tags: java
---


> 操作系统知识总结

##  目录
* 目录
{:toc}
# 一、OS内存管理

对于内存的管理来说有三两种，分页式管理、分段式管理和段页式管理。既然要搞些辅助的东西，那么就需要使用一些记忆表进行去管理，可以划定一个固定的分区进行记忆，其实就类似于JVM中的记忆集。

## 1.1分页式

分页式即将内存分为大小为4kb的页，然后生成一个页表，通过页表将离散的页进行连续化，即通过页表的地址找到对应的物理地址，虽然是物理上是不连续的，但是可以做到逻辑上连续，这样可以解决内存分块的问题，防止有些内存过大或者过小不能使用。

在分页是内存管理中，有两个很重要的点：

- 虚拟地址到物理地址的转换要快
- 解决虚拟地址空间大，页表也会很大的问题。
- 其实有点类似于索引的感觉，先划分范围然后进行快速的查找，相当于说，操作系统中进行最多的操作就是查找操作。

### 快表

为了解决虚拟地址到物理地址的转换速度，操作系统在页表方案基础上引入了快表来加速虚拟地址到物理地址的转换，我们可以把快表理解为一种特殊的高速缓存存储器，其中的内容是页表的一部分或者是全部内容，作为页表的cache，他的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据是CPU要访问两次主存，有了快表，有时只需要访问一次高速缓存器，一次主存这样可以加速查找并提高指令执行速度。**即里面直接存储这映射关系。**

使用快表之后的地址转换流程是这样的：

1. 根据虚拟地址中的页号查找快表
2. 如果该页在快表中，直接从快表中读取相应的物理地址
3. 如果该页不在快表中，就直接访问内存中的页表，在从页表中得到物理地址，同时将页表中的该映射表项添加到快表中。
4. 当快表填满后，又要登记新表时，就按照一定的淘汰策略淘汰掉快表中的一个页。

其实也就是利用了程序的局部性原理，一次用过的数据之后很可能还会再用，比如各种for循环。

这里面就会涉及到内存的淘汰算法，LRU  LFU等等。这里面也和redis有点类似，可以说是redis应该是借鉴了操作系统的设计模式。

### 多级页表

引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多的空间，特别是那些根本不需要的页表就不需要保留在内存中，多级页表属于时间换空间的典型场景。

## 1.2分段式

但是上面的分页只是便于CPU进行管理访问内存，大小为4KB没有什么现实的意义。还有一种就是分段式管理，即对于程序来说有不同的代码段，那么就可以根据代码段的长度进行内存的管理，即根据代码段需要的内存长度直接在物理内存上分配一个一样长度的连续内存块，这样CPU在执行程序的时候就可以直接的连续访问，但是也需要段表进行直接的地址访问。

总的来说，对于程序来说，**分页**的方式就是物理上**不连续**的内存空间，**分段**就是根据程序需要的内存大小直接分配**连续**的内存空间。

分页可以提高内存的利用率，而分段则可以加快程序的执行速度，不需要地址的映射计算。另外，分段式内存中需要存储段表。

## 1.3段页式

即将分段和分页结合起来，然后进行联合控制。

首先将物理地址进行分页，形成页表，然后将页表进行分段，形成段表，这样就形成了逻辑上连续的程序段内存空间，方便代码的执行与运行。

此时逻辑地址为 ： 段号+段内页号+页内地址。 即通过页内地址找到对应的物理地址，相当于需要做到两次的转换才能找到对应的物理地址。

# 二、虚拟存储器

基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其他部分留在外存，然后就可以启动程序执行。由于外存比内存大很多，所以我们运行的程序内存大小实际上是可以比计算机系统实际的内存大小更大的，另外在程序执行过程中，当所访问的信息不再内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统也会将内存中暂时不使用的内容换到外存上，从而腾出空间存放将要调入内存的信息。这样计算机好像为用户提供了一个比实际内存大的多的存储器----**虚拟存储器**。

虚拟存储器主要解决了三个重要的功能：

1. 它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。
2. 它为每个进程提供了一致的地址空间，从而简化了存储器管理。
3. 它保护了每个进程的地址空间不被其他进程破坏。

由于进程拥有自己独占的虚拟地址空间，CPU通过地址翻译将虚拟地址转换成真实的物理地址，每个进程只能访问自己的地址空间。因此，在没有其他机制（进程间通信）的辅助下，进程之间是无法共享数据的。所以虚拟存储器引出了线程之间的数据交互的问题。

## 一、虚拟地址

基于虚拟存储器的概念，那么程序直接操作的地址就是虚拟地址而不是具体的物理地址。很显然在进行编写代码的时候，直观上都是从索引为0的地址空间进行操作，比如说一个文本都是从0行开始写，但是具体到内存的物理空间来说，0行只有一个，如果多个程序同时写那是肯定不行的，所以需要虚拟出来多个0行，实现多个程序共享，这也就是虚拟地址的概念。所以说也需要一个虚拟地址的转换工作。一般使用的是内存管理单元 Memory Management Unit MMU的硬件，将虚拟地址翻译成对应的物理地址。

## 二、虚拟内存

虚拟存储器也解决了占用大量内存数据的读取问题。很多时候点开了很多占用内存的软件，这些软件占用的内存可能已经远远超过我们电脑内存本身所具有的本身，但是为啥还能用呢？这其实就是运用了虚拟内存的技术，即**虚拟内存可以让程序拥有超过系统物理内存大小的可用空间**。

另外**虚拟内存为每个进程提供了一个一致的、私有的地址空间，**它让每个进程产生了一种自己是在独享主存的错觉(每个进程都拥有一片连续完整的内存空间)，这样会更加有效的管理内存并减少出错。

其实主要的技术就是将硬盘扩展内存，即并不是一次性将程序需要的数据一次性加载进来，而是利用程序的局部性原理，只将需要的数据加载进来，

> 虚拟内存使得应用程序认为他拥有连续的可用内存(一个连续完整的地址空间)，而实际上，他通常是被分隔成为多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的的系统使得大型程序的编写变得更容易，对真正的物理内存的使用率也更有效率。目前，大多数操作系统都使用了虚拟内存，如windows家族的虚拟内存，Linux的交换空间等。

## 局部性原理

其实存储器能够运用，使用的就是局部性原理，同理cache的运行也是该原理。 表现在两个方面：

- 时间局部性：如果程序中的某条指令一旦执行，不久后该指令可能还会再次执行，如果某数据被访问过，不久后该数据还可能被再次访问。
- 空间局部性：一旦程序访问了某个存储单元，不久后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内。

# 三、虚拟存储器的技术实现

## 1.请求分页存储管理

建立在分页管理之上,为了支持虛拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的法。请求分页存储管理系统中,在作业开始运行之前,仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存,则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存,同时操作系统也可以将暂时不用的页面置换到外存中。

## 2.请求分段式存储管理

建立在分段存储管理之上,增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样,在作业开始运行之前,仅装入当前要执行的部分段即可运行;在执行过程中,可使用请求调入中断动态装入要访问但又不在内存的程序段;当内存空间已满,而又需要装入新的段时,根据置换功能适当调出某个段,以便腾出空间而装入新的段。

## 3.请求段页式存储管理

建立在段页式存储管理之上。

# 四、页面置换算法

虚拟内存管理的一个很重要的概念，即哪些内存中的数据要被替换？如何进行替换？

- OPT页面置换算法(最佳页面置换算法)
  - 理想情况下的算法
- FIFO页面置换算法(先进先出页面置换算法)
  - 总是淘汰最先进入内存的页面，选择在内存中驻留时间最久的页面进行淘汰
- LRU页面置换算法(最近未使用页面置换算法)
  - Least Currently Used 算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问依赖所经历的时间T，当需要淘汰一个页面时，选择现有的页面中其T值最大的，即最近最久未使用的页面予以淘汰。
- LFU页面置换算法(最少使用页面排序算法)
  - Least Frequently Used 算法会将系统维护一个按最近一次访问时间排序的页面链表，链表首节点是最近刚刚使用过的页面，链表尾节点是最久为使用的页面，访问内存时，找到相应的页面，并把它移动到链表之首，缺页时，置换链表尾结点的页面，也就是说内存内使用越频繁的页面，被保留的时间也相对越长。

# 五、Cache映射算法

cache映射算法总共有三种：

- 直接映射
- 全相连映射
- 组相连映射

### 直接映射

其中直接相连是最简单的，即cache中的一个快只能映射到内存中的一个块。  

直接映射是最简单的地址映射方式，它的硬件简单，成本低，地址变换速度快，而且不涉及替换[算法](http://lib.csdn.net/base/datastructure)问题。但是这种方式不够灵活，Cache的存储空间得不到充分利用，每个主存块只有一个固定位置可存放，容易产生冲突，使Cache效率下降，因此只适合大容量Cache采用。例如，如果一个程序需要重复引用主存中第0块与第16块，最好将主存第0块与第16块同时复制到Cache中，但由于它们都只能复制到Cache的第0块中去，即使Cache中别的存储空间空着也不能占用，因此这两个块会不断地交替装入Cache中，导致命中率降低。

### 全相连映射

这种是cache中的每一块都可以映射到内存中的任何一块，这种实现的方式最为灵活，但是其实现比较复杂，并且成本很高。

 全相联映射方式比较灵活，主存的各块可以映射到Cache的任一块中，Cache的利用率高，块冲突概率低，只要淘汰Cache中的某一块，即可调入主存的任一块。但是，由于Cache比较电路的设计和实现比较困难，这种方式只适合于小容量Cache采用。

### 组相连映射

这种就是结合和直接映射和全相连映射的特点，是一种折中的能够接受的方案。即cache和内存都分组，组与组是直接映射的，但是在组内是全相连映射。

主存和Cache都分组，主存中一个组内的块数与Cache中的分组数相同，组间采用直接映射，组内采用全相联映射。也就是说，将Cache分成u组，每组v块，主存块存放到哪个组是固定的，至于存到该组哪一块则是灵活的。例如，主存分为256组，每组8块，Cache分为8组，每组2块。

# 六、进程与线程

参考链接：

- [一文讲透进程与线程知识](https://mp.weixin.qq.com/s/kcsvBr08wcxGYWE9vPC0QQ)

## 进程

进程-操作系统提供的抽象概念，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。程序是指令、数据及其组织形式的描述，进程是程序的实体。程序本身是没有生命周期的，它只是存在磁盘上的一些指令,程序一旦运行就是进程。

当程序需要运行时，操作系统将代码和所有静态数据记载到内存和进程的地址空间（每个进程都拥有唯一的地址空间，见下图所示）中，通过创建和初始化栈（局部变量，函数参数和返回地址)、分配堆内存以及与IO相关的任务，当前期准备工作完成，启动程序，OS将CPU的控制权转移到新创建的进程，进程开始运行。

进程可以包含多个线程，而进程拥有独立的内存空间，就相当于一个应用程序，但是线程是属于进程的，其内存空间是共享的，所以需要进行信号量的控制。

## 线程

线程-也是操作系统提供的抽象概念，是程序执行中一个单一的顺序控制流程，是程序执行流的最小单元，是处理器调度和分派的基本单位。一个进程可以有一个或多个线程，同一进程中的多个线程将共享该进程中的全部系统资源，如虚拟地址空间，文件描述符和信号处理等等。但同一进程中的多个线程有各自的调用栈和线程本地存储。

#### 进程 VS 线程

- 进程是资源的分配和调度的独立单元。进程拥有完整的虚拟地址空间，当发生进程切换时，不同的进程拥有不同的虚拟地址空间。而同一进程的多个线程是可以共享同一地址空间
- 线程是CPU调度的基本单元，一个进程包含若干线程。
- 线程比进程小，基本上不拥有系统资源。线程的创建和销毁所需要的时间比进程小很多
- 由于线程之间能够共享地址空间，因此，需要考虑同步和互斥操作
- 一个线程的意外终止会影响整个进程的正常运行，但是一个进程的意外终止不会影响其他的进程的运行。因此，多进程程序安全性更高。

## 协程

协程（Coroutine，又称微线程）是一种比线程更加轻量级的存在，协程不是被操作系统内核所管理，而完全是由程序所控制。协程与线程以及进程的关系见下图所示。

- 协程可以比作子程序，但执行过程中，子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。协程之间的切换不需要涉及任何系统调用或任何阻塞调用
- 协程只在一个线程中执行，是子程序之间的切换，发生在用户态上。而且，线程的阻塞状态是由操作系统内核来完成，发生在内核态上，因此协程相比线程节省线程创建和切换的开销
- 协程中不存在同时写变量冲突，因此，也就不需要用来守卫关键区块的同步性原语，比如互斥锁、信号量等，并且不需要来自操作系统的支持。

协程适用于IO阻塞且需要大量并发的场景，当发生IO阻塞，由协程的调度器进行调度，通过将数据流yield掉，并且记录当前栈上的数据，阻塞完后立刻再通过线程恢复栈，并把阻塞的结果放到这个线程上去运行。